{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "\n",
    "from config import Cfg as cfg\n",
    "\n",
    "import mysql.connector\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Race results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnx = mysql.connector.connect(user=cfg.mysql_user, database=cfg.mysql_db, password=cfg.mysql_pw, ssl_disabled=True)\n",
    "\n",
    "query = \"SELECT * FROM results;\"\n",
    "\n",
    "# execute the query and assign it to a pandas dataframe\n",
    "df_results = pd.read_sql(query, con=cnx)\n",
    "\n",
    "cnx.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "643055"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_results.athlete.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Races info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnx = mysql.connector.connect(user=cfg.mysql_user, database=cfg.mysql_db, password=cfg.mysql_pw, ssl_disabled=True)\n",
    "\n",
    "query = \"SELECT * FROM races;\"\n",
    "# execute the query and assign it to a pandas dataframe\n",
    "df_races = pd.read_sql(query, con=cnx)\n",
    "\n",
    "cnx.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some processing on the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------\n",
    "# -- RACES --\n",
    "# -----------\n",
    "\n",
    "\n",
    "# keep only active races\n",
    "df_races = df_races.loc[df_races['info'].dropna().index]\n",
    "\n",
    "# remove duplicates\n",
    "df_races = df_races.loc[df_races.race != 'worldchampionship70.3m']\n",
    "\n",
    "# remove worldchampionship\n",
    "df_races = df_races.loc[df_races.race != 'worldchampionship70.3']\n",
    "df_races = df_races.loc[df_races.race != 'worldchampionship']\n",
    "\n",
    "\n",
    "# add Country codes\n",
    "with open(\"./../data/geo-data/races_geo_info.json\", 'r') as f:\n",
    "    races_geo_info = json.loads(f.read())\n",
    "             \n",
    "df_races['country_code'] = None\n",
    "for race in df_races.race.values:\n",
    "    country_code = races_geo_info[race]\n",
    "    df_races.loc[df_races.race == race, 'country_code'] = races_geo_info[race]['components']['ISO_3166-1_alpha-3']\n",
    "\n",
    "# -----------\n",
    "# -- RESULTS --\n",
    "# -----------\n",
    "\n",
    "# worldchampionship70.3 and worldchampionship70.3m are the same race\n",
    "df_results.loc[df_results.race == \"worldchampionship70.3m\", 'race'] = 'worldchampionship70.3'\n",
    "\n",
    "# keep only results of non discontinued races\n",
    "df_results = df_results[df_results['race'].isin(df_races['race'])]\n",
    "\n",
    "# extract gender from division\n",
    "df_results['gender'] = df_results['division'].apply(lambda x: x[0])\n",
    "\n",
    "# convert date to datetime\n",
    "df_results['date'] = pd.to_datetime(df_results['date'])\n",
    "\n",
    "# str to int\n",
    "df_results['year'] = df_results['year'].apply(int)\n",
    "\n",
    "# keep only results from before 2019\n",
    "df_results = df_results.loc[df_results['year'] < 2019]\n",
    "\n",
    "# discard pro athletes\n",
    "df_results = df_results.loc[df_results.division.str.contains(\"PRO\") == False]\n",
    "\n",
    "# Add gender\n",
    "df_results['gender'] = None\n",
    "df_results.loc[df_results['division'].str.contains(\"M\"), 'gender'] = \"M\"\n",
    "df_results.loc[df_results['division'].str.contains(\"F\"), 'gender'] = \"F\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### what do we have left to work with?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Results dataset --\n",
      "  Number of single results: 1592599\n",
      "  Number of athletes: 575481\n",
      "-- Races dataset --\n",
      "  Number of active races: 157\n"
     ]
    }
   ],
   "source": [
    "print('-- Results dataset --')\n",
    "print(f\"  Number of single results: {len(df_results)}\")\n",
    "print(f\"  Number of athletes: {len(df_results.athlete.unique())}\")\n",
    "\n",
    "print('-- Races dataset --')\n",
    "print(f\"  Number of active races: {len(df_races)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Race count and unique race count per athlete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To prevent cold-start problem keep only people with at least 2 different races."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of different individuals: 248360\n",
      "Number of single results: 1190216\n"
     ]
    }
   ],
   "source": [
    "# total number of races per athlete\n",
    "athletes_count_races = (df_results.groupby('athlete')['division']\n",
    "     .size()\n",
    "     .reset_index()\n",
    "     .rename(columns={'division': 'n_races'})\n",
    ")\n",
    "\n",
    "# total number of different races per athlete\n",
    "athletes_count_diff_races = (df_results\n",
    "     .groupby(['athlete', 'race'])\n",
    "     .size()\n",
    "     .reset_index()\n",
    "     .groupby('athlete')\n",
    "     .size()\n",
    "     .reset_index()\n",
    "     .rename(columns={0: 'n_different_races'})\n",
    ")\n",
    "\n",
    "# merge the two so we can filter from that\n",
    "athlete_habits = athletes_count_diff_races.merge(athletes_count_races, left_on=\"athlete\", right_on=\"athlete\", how=\"left\")\n",
    "\n",
    "# What we are filtering with\n",
    "min_count_diff_races = 2\n",
    "max_count_races = 100 # probably similar names\n",
    "\n",
    "valid_athletes = athlete_habits.loc[(athlete_habits['n_different_races']>=min_count_diff_races) & (athlete_habits['n_races']<=max_count_races)]\n",
    "\n",
    "# use this df to filter original results data\n",
    "df_results_filtered = df_results.loc[df_results['athlete'].isin(valid_athletes['athlete'])]\n",
    "df_results_filtered = df_results_filtered.merge(valid_athletes, left_on=\"athlete\", right_on=\"athlete\", how=\"left\")\n",
    "\n",
    "# Anonimize entrants\n",
    "user_hash = {}\n",
    "\n",
    "for i,user in enumerate(df_results_filtered.athlete.unique()):\n",
    "    user_hash[user] = f'u{i}'\n",
    "df_results_filtered.loc[:, 'athlete'] = df_results_filtered.athlete.map(lambda x: user_hash[x])\n",
    "\n",
    "print(\"Number of different individuals:\", len(valid_athletes))\n",
    "print(\"Number of single results:\", len(df_results_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>athlete</th>\n",
       "      <th>division</th>\n",
       "      <th>rankdiv</th>\n",
       "      <th>rankgender</th>\n",
       "      <th>rankoverall</th>\n",
       "      <th>swim</th>\n",
       "      <th>t1</th>\n",
       "      <th>bike</th>\n",
       "      <th>t2</th>\n",
       "      <th>...</th>\n",
       "      <th>country</th>\n",
       "      <th>date</th>\n",
       "      <th>fulldata</th>\n",
       "      <th>score</th>\n",
       "      <th>swim_score</th>\n",
       "      <th>run_score</th>\n",
       "      <th>bike_score</th>\n",
       "      <th>gender</th>\n",
       "      <th>n_different_races</th>\n",
       "      <th>n_races</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1518207</td>\n",
       "      <td>u0</td>\n",
       "      <td>M75-79</td>\n",
       "      <td>1</td>\n",
       "      <td>1073</td>\n",
       "      <td>1209</td>\n",
       "      <td>2440</td>\n",
       "      <td>678</td>\n",
       "      <td>11150</td>\n",
       "      <td>469</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>2016-11-13</td>\n",
       "      <td>0</td>\n",
       "      <td>98.4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>86.1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>M</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1518209</td>\n",
       "      <td>u1</td>\n",
       "      <td>M75-79</td>\n",
       "      <td>2</td>\n",
       "      <td>1141</td>\n",
       "      <td>1301</td>\n",
       "      <td>3539</td>\n",
       "      <td>679</td>\n",
       "      <td>13127</td>\n",
       "      <td>461</td>\n",
       "      <td>...</td>\n",
       "      <td>JPN</td>\n",
       "      <td>2016-11-13</td>\n",
       "      <td>0</td>\n",
       "      <td>97.1</td>\n",
       "      <td>77.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>90.7</td>\n",
       "      <td>M</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1518210</td>\n",
       "      <td>u2</td>\n",
       "      <td>M65-69</td>\n",
       "      <td>1</td>\n",
       "      <td>181</td>\n",
       "      <td>202</td>\n",
       "      <td>1895</td>\n",
       "      <td>377</td>\n",
       "      <td>9944</td>\n",
       "      <td>243</td>\n",
       "      <td>...</td>\n",
       "      <td>AUS</td>\n",
       "      <td>2016-11-13</td>\n",
       "      <td>0</td>\n",
       "      <td>99.9</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.7</td>\n",
       "      <td>M</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1518211</td>\n",
       "      <td>u3</td>\n",
       "      <td>M80-84</td>\n",
       "      <td>1</td>\n",
       "      <td>1281</td>\n",
       "      <td>1475</td>\n",
       "      <td>3135</td>\n",
       "      <td>784</td>\n",
       "      <td>13528</td>\n",
       "      <td>726</td>\n",
       "      <td>...</td>\n",
       "      <td>JPN</td>\n",
       "      <td>2016-11-13</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>M</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1518213</td>\n",
       "      <td>u4</td>\n",
       "      <td>M55-59</td>\n",
       "      <td>1</td>\n",
       "      <td>134</td>\n",
       "      <td>152</td>\n",
       "      <td>2150</td>\n",
       "      <td>350</td>\n",
       "      <td>9711</td>\n",
       "      <td>282</td>\n",
       "      <td>...</td>\n",
       "      <td>ESP</td>\n",
       "      <td>2016-11-13</td>\n",
       "      <td>0</td>\n",
       "      <td>99.6</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.3</td>\n",
       "      <td>99.0</td>\n",
       "      <td>M</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id athlete division  rankdiv  rankgender  rankoverall  swim   t1  \\\n",
       "0  1518207      u0   M75-79        1        1073         1209  2440  678   \n",
       "1  1518209      u1   M75-79        2        1141         1301  3539  679   \n",
       "2  1518210      u2   M65-69        1         181          202  1895  377   \n",
       "3  1518211      u3   M80-84        1        1281         1475  3135  784   \n",
       "4  1518213      u4   M55-59        1         134          152  2150  350   \n",
       "\n",
       "    bike   t2  ...  country       date  fulldata  score swim_score  run_score  \\\n",
       "0  11150  469  ...      USA 2016-11-13         0   98.4      100.0       86.1   \n",
       "1  13127  461  ...      JPN 2016-11-13         0   97.1       77.2      100.0   \n",
       "2   9944  243  ...      AUS 2016-11-13         0   99.9      100.0      100.0   \n",
       "3  13528  726  ...      JPN 2016-11-13         0  100.0      100.0      100.0   \n",
       "4   9711  282  ...      ESP 2016-11-13         0   99.6      100.0       98.3   \n",
       "\n",
       "  bike_score gender  n_different_races  n_races  \n",
       "0      100.0      M                  7       10  \n",
       "1       90.7      M                  7       12  \n",
       "2       99.7      M                 12       24  \n",
       "3      100.0      M                  5       15  \n",
       "4       99.0      M                  6        9  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_results_filtered['n_races'].hist(bins=np.arange(-0.99, 100.99, 1), figsize=(8, 3))\n",
    "df_results_filtered.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A majority of athletes have < 20 races"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL 1: the more you do a race, the more you implicitely like it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count of each race for each entrants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>athlete</th>\n",
       "      <th>race</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u0</td>\n",
       "      <td>brazil</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u0</td>\n",
       "      <td>california70.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u0</td>\n",
       "      <td>cozumel</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u0</td>\n",
       "      <td>honu70.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u0</td>\n",
       "      <td>loscabos</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  athlete            race  count\n",
       "0      u0          brazil      1\n",
       "1      u0  california70.3      1\n",
       "2      u0         cozumel      2\n",
       "3      u0        honu70.3      1\n",
       "4      u0        loscabos      2"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_data = (\n",
    "    df_results_filtered\n",
    "        .groupby(['athlete', 'race'])\n",
    "        .size()\n",
    "        .reset_index()\n",
    "        .rename(columns={0: 'count'})\n",
    ")\n",
    "\n",
    "results_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many times the race has been done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>total_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arizona70.3</td>\n",
       "      <td>5485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DunLaoghaire70.3</td>\n",
       "      <td>896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Florianopolis70.3</td>\n",
       "      <td>916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Haugesund70.3</td>\n",
       "      <td>2153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IMsubicbay</td>\n",
       "      <td>1152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                race  total_count\n",
       "0        Arizona70.3         5485\n",
       "1   DunLaoghaire70.3          896\n",
       "2  Florianopolis70.3          916\n",
       "3      Haugesund70.3         2153\n",
       "4         IMsubicbay         1152"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "race_popularity = (results_data\n",
    "    .groupby(by = ['race'])['count']\n",
    "    .sum()\n",
    "    .reset_index()\n",
    "    .rename(columns = {'count': 'total_count'})\n",
    ")\n",
    "race_popularity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count      153.000000\n",
      "mean      7779.189542\n",
      "std       7610.135006\n",
      "min        313.000000\n",
      "25%       2375.000000\n",
      "50%       4784.000000\n",
      "75%      11083.000000\n",
      "max      38737.000000\n",
      "Name: total_count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(race_popularity['total_count'].describe())\n",
    "# print(race_popularity['total_count'].quantile(np.arange(.5, 1, .01)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add demographics info for users (if we want to filter later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>athlete</th>\n",
       "      <th>race</th>\n",
       "      <th>count</th>\n",
       "      <th>total_count</th>\n",
       "      <th>gender</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u0</td>\n",
       "      <td>brazil</td>\n",
       "      <td>1</td>\n",
       "      <td>12516</td>\n",
       "      <td>M</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u0</td>\n",
       "      <td>california70.3</td>\n",
       "      <td>1</td>\n",
       "      <td>29870</td>\n",
       "      <td>M</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u0</td>\n",
       "      <td>cozumel</td>\n",
       "      <td>2</td>\n",
       "      <td>16438</td>\n",
       "      <td>M</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u0</td>\n",
       "      <td>honu70.3</td>\n",
       "      <td>1</td>\n",
       "      <td>15449</td>\n",
       "      <td>M</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u0</td>\n",
       "      <td>loscabos</td>\n",
       "      <td>2</td>\n",
       "      <td>3532</td>\n",
       "      <td>M</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>u0</td>\n",
       "      <td>mardelplata</td>\n",
       "      <td>1</td>\n",
       "      <td>1847</td>\n",
       "      <td>M</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>u0</td>\n",
       "      <td>xiamen70.3</td>\n",
       "      <td>2</td>\n",
       "      <td>2185</td>\n",
       "      <td>M</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>u1</td>\n",
       "      <td>cairns</td>\n",
       "      <td>1</td>\n",
       "      <td>7298</td>\n",
       "      <td>M</td>\n",
       "      <td>JPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>u1</td>\n",
       "      <td>canada70.3</td>\n",
       "      <td>1</td>\n",
       "      <td>2539</td>\n",
       "      <td>M</td>\n",
       "      <td>JPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>u1</td>\n",
       "      <td>honu70.3</td>\n",
       "      <td>3</td>\n",
       "      <td>15449</td>\n",
       "      <td>M</td>\n",
       "      <td>JPN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  athlete            race  count  total_count gender country\n",
       "0      u0          brazil      1        12516      M     USA\n",
       "1      u0  california70.3      1        29870      M     USA\n",
       "2      u0         cozumel      2        16438      M     USA\n",
       "3      u0        honu70.3      1        15449      M     USA\n",
       "4      u0        loscabos      2         3532      M     USA\n",
       "5      u0     mardelplata      1         1847      M     USA\n",
       "6      u0      xiamen70.3      2         2185      M     USA\n",
       "7      u1          cairns      1         7298      M     JPN\n",
       "8      u1      canada70.3      1         2539      M     JPN\n",
       "9      u1        honu70.3      3        15449      M     JPN"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender = (df_results_filtered\n",
    "     .groupby(['athlete', 'gender'])\n",
    "     .size()\n",
    "     .reset_index()\n",
    "     .rename(columns={0: 'n'})\n",
    "     .pivot(index='athlete', columns='gender', values='n')\n",
    "     .idxmax(axis=1)\n",
    "     .rename('gender')\n",
    ")\n",
    "\n",
    "country = (df_results_filtered\n",
    "     .groupby(['athlete', 'country'])\n",
    "     .size()\n",
    "     .reset_index()\n",
    "     .rename(columns={0: 'n'})\n",
    "     .pivot(index='athlete', columns='country', values='n')\n",
    "     .idxmax(axis=1)\n",
    "     .rename('country')\n",
    ")\n",
    "\n",
    "user_data_with_race_count = results_data.merge(race_popularity, left_on = 'race', right_on = 'race', how = 'left')\n",
    "user_data_with_race_count = user_data_with_race_count.merge(gender, left_on = 'athlete', right_on = 'athlete', how = 'left')\n",
    "user_data_with_race_count = user_data_with_race_count.merge(country, left_on = 'athlete', right_on = 'athlete', how = 'left')\n",
    "user_data_with_race_count.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --## -- Implemeting the Nearest Neighbor Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshaping the Data\n",
    "\n",
    "For K-Nearest Neighbors, we want the data to be in an m x n array, where m is the number of artists and n is the number of users. To reshape the dataframe, we’ll pivot the dataframe to the wide format with artists as rows and users as columns. Then we’ll fill the missing observations with 0s since we’re going to be performing linear algebra operations (calculating distances between vectors). Finally, we transform the values of the dataframe into a scipy sparse matrix for more efficient calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, save_npz\n",
    "\n",
    "wide_race_data = user_data_with_race_count.pivot(index = 'race', columns = 'athlete', values = 'count').fillna(0)\n",
    "wide_race_data_sparse = csr_matrix(wide_race_data.values)\n",
    "\n",
    "save_npz('./../data/matrices/ironman_sparse_race_matrix.npz', wide_race_data_sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting the Model\n",
    "\n",
    "Time to implement the model. We’ll initialize the NearestNeighbors class as model_knn and fit our sparse matrix to the instance. By specifying the metric = cosine, the model will measure similarity bectween artist vectors by using cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='brute', leaf_size=30, metric='cosine',\n",
       "         metric_params=None, n_jobs=None, n_neighbors=5, p=2, radius=1.0)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "model_knn = NearestNeighbors(metric = 'cosine', algorithm = 'brute')\n",
    "model_knn.fit(wide_race_data_sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making Recommendations\n",
    "\n",
    "And we’re finally ready to make some recommendations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for luxembourg70.3:\n",
      "\n",
      "1: Maastricht, with distance of 0.8463307204521767.\n",
      "2: kraichgau70.3, with distance of 0.86239924603374.\n",
      "3: vichy70.3, with distance of 0.8747842882051549.\n",
      "4: france70.3, with distance of 0.8835074758269879.\n",
      "5: germany, with distance of 0.885978112704221.\n",
      "6: salzburg70.3, with distance of 0.9013549242911323.\n",
      "7: switzerland70.3, with distance of 0.9054399606701558.\n",
      "8: mallorca70.3, with distance of 0.9073549633527157.\n",
      "9: challengeroth, with distance of 0.9146828699568916.\n"
     ]
    }
   ],
   "source": [
    "query_index = np.random.choice(wide_race_data.shape[0])\n",
    "distances, indices = model_knn.kneighbors(wide_race_data.iloc[query_index, :].values.reshape(1, -1), n_neighbors = 10)\n",
    "\n",
    "for i in range(0, len(distances.flatten())):\n",
    "    if i == 0:\n",
    "        print(f'Recommendations for {wide_race_data.index[query_index]}:\\n')\n",
    "    else:\n",
    "        print(f'{i}: {wide_race_data.index[indices.flatten()[i]]}, with distance of {distances.flatten()[i]}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL 2: Binary racing. Either an entrants raced a race or not\n",
    "\n",
    "Previously, we used the actual play counts as values in our artist vectors. Another approach would be convert each vector into a binary (1 or 0): either a user played the song or they did not. We can do this by applying the `sign` function in `numpy` to each column in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_race_data_zero_one = wide_race_data.apply(np.sign)\n",
    "wide_race_data_zero_one_sparse = csr_matrix(wide_race_data_zero_one.values)\n",
    "\n",
    "save_npz('./../data/matrices/ironman_sparse_race_matrix_binary.npz', wide_race_data_zero_one_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='brute', leaf_size=30, metric='cosine',\n",
       "         metric_params=None, n_jobs=None, n_neighbors=5, p=2, radius=1.0)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_knn_binary = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "model_knn_binary.fit(wide_race_data_zero_one_sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let’s make a quick comparison. Which recommendations look better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for luxembourg70.3:\n",
      "\n",
      "1: kraichgau70.3, with distance of 0.8200678531640405.\n",
      "2: Maastricht, with distance of 0.856314601686226.\n",
      "3: germany, with distance of 0.863504262560558.\n",
      "4: france70.3, with distance of 0.8666462916268989.\n",
      "5: vichy70.3, with distance of 0.8675706711938609.\n",
      "6: switzerland70.3, with distance of 0.8699505420804321.\n",
      "7: salzburg70.3, with distance of 0.8828284015654798.\n",
      "8: mallorca70.3, with distance of 0.8882372313465947.\n",
      "9: challengeroth, with distance of 0.9005335958073152.\n"
     ]
    }
   ],
   "source": [
    "distances, indices = model_knn_binary.kneighbors(wide_race_data_zero_one.iloc[query_index, :].values.reshape(1, -1), n_neighbors = 10)\n",
    "\n",
    "for i in range(0, len(distances.flatten())):\n",
    "    if i == 0:\n",
    "        print(f'Recommendations for {wide_race_data_zero_one.index[query_index]}:\\n')\n",
    "    else:\n",
    "        print(f'{i}: {wide_race_data_zero_one.index[indices.flatten()[i]]}, with distance of {distances.flatten()[i]}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The binary data representation recommendations look qualitatively similar.\n",
    "\n",
    "Again, it’s not obvious which method is better. Since ultimately it’s the users’s future actions that indicate which recommender system is better, it’s a perfect candidate for A/B Testing. For now, I’ll stick with the non-binary data representation model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement pre-filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/miniconda3/envs/data-science/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "race_filter = df_races[['race', 'region', 'country_code']]\n",
    "race_filter['is_70.3'] = race_filter['race'].str.contains('70.3')\n",
    "race_filter = race_filter.set_index('race')\n",
    "race_filter.head()\n",
    "\n",
    "# make sure the filtering df has the same data/order than the wide_race_data\n",
    "df_to_filter_races = pd.DataFrame(list(wide_race_data.index.map(lambda x: race_filter.loc[x].to_dict())), index=wide_race_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((153, 3), (157, 3))"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_to_filter_races.shape, race_filter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filtered_races(filterBy, value, df=df_to_filter_races, returnIndices=False):\n",
    "    if not filterBy:\n",
    "        selection = df\n",
    "    else:\n",
    "        selection = df.loc[df[filterBy] == value]\n",
    "    if returnIndices:\n",
    "        return selection.index.map(lambda x: df.index.get_loc(x)).tolist()\n",
    "    else:\n",
    "        return selection.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(similarTo, n=10, filterBy=False, value=False):\n",
    "    if filterBy:\n",
    "        selection_races = get_filtered_races(filterBy, value, df=df_to_filter_races)\n",
    "        data = user_data_with_race_count.loc[user_data_with_race_count['race'].isin(selection_races)]\n",
    "    else:\n",
    "        data = user_data_with_race_count\n",
    "    wide_data = data.pivot(index = 'race', columns = 'athlete', values = 'count')\n",
    "    \n",
    "    if similarTo not in wide_data.index:\n",
    "        row_to_add = (user_data_with_race_count\n",
    "                          .loc[user_data_with_race_count['race'] == similarTo]\n",
    "                          .pivot(index='race', columns='athlete', values='count')\n",
    "                     )\n",
    "        # add row back if it was filtered out\n",
    "        wide_data = pd.concat([wide_data, row_to_add], sort=False)\n",
    "    wide_data.fillna(0, inplace=True)\n",
    "    data_sparse = csr_matrix(wide_data.values)\n",
    "        \n",
    "    model_nn_binary = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "    model_nn_binary.fit(data_sparse)\n",
    "    query_index = np.where(wide_data.index == similarTo)[0][0]\n",
    "    distances, indices = model_nn_binary.kneighbors(wide_data.iloc[query_index, :].values.reshape(1, -1), n_neighbors = n+1)\n",
    "    distances = distances.flatten()\n",
    "    indices = indices.flatten()\n",
    "    return [(wide_data.index[indices[i]], distances[i]) for i in range(1, len(distances))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('arizona', 0.7861915846702664),\n",
       " ('california70.3', 0.8516627809813649),\n",
       " ('stgeorge70.3', 0.8694722935189386),\n",
       " ('indianwellslaquinta70.3', 0.8920661774114591),\n",
       " ('santarosa70.3', 0.9032628733428057),\n",
       " ('boulder70.3', 0.9128008544891082),\n",
       " ('superfrog70.3', 0.923165281195798),\n",
       " ('coeurdalene70.3', 0.9243375258295179),\n",
       " ('santacruz70.3', 0.9303157440175995),\n",
       " ('boulder', 0.9314105332245298)]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prediction('Arizona70.3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('arizona', 0.7861915846702664),\n",
       " ('boulder', 0.9314105332245298),\n",
       " ('santarosa', 0.9458733001072461),\n",
       " ('texas', 0.9574168738453601),\n",
       " ('st.george', 0.9622583796527981),\n",
       " ('canada', 0.9629124576963345),\n",
       " ('florida', 0.9687432184274619),\n",
       " ('louisville', 0.9691280053694747),\n",
       " ('wisconsin', 0.971610079426734),\n",
       " ('chattanooga', 0.9731856992862584)]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prediction('Arizona70.3', filterBy='is_70.3', value=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faster prediction by pre-computing the matrix and fitting the model prior and filtering on the full results data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precompute similarity matrix and do filtering as post-process\n",
    "wide_race_data = user_data_with_race_count.pivot(index = 'race', columns = 'athlete', values = 'count').fillna(0)\n",
    "wide_race_data_sparse = csr_matrix(wide_race_data.values)\n",
    "\n",
    "model_knn = NearestNeighbors(metric = 'cosine', algorithm = 'brute')\n",
    "model_knn.fit(wide_race_data_sparse)\n",
    "\n",
    "# make sure the filtering df has the same data/order than the wide_race_data\n",
    "df_to_filter_races = pd.DataFrame(list(wide_race_data.index.map(lambda x: race_filter.loc[x].to_dict())), index=wide_race_data.index)\n",
    "\n",
    "def get_prediction_fast(similarTo, n=10, filterBy=False, value=False):\n",
    "    query_index = np.where(wide_race_data.index == similarTo)[0][0]\n",
    "    total_n = wide_race_data.shape[0]\n",
    "    distances, indices = model_knn.kneighbors(wide_race_data.iloc[query_index].values.reshape(1, -1), n_neighbors = total_n)\n",
    "    distances = distances.flatten()\n",
    "    indices = indices.flatten()\n",
    "    \n",
    "    if filterBy:\n",
    "        selection_idx = get_filtered_races(filterBy, value, df=df_to_filter_races, returnIndices=False)\n",
    "        n = n if n<len(selection_idx) else len(selection_idx)\n",
    "        out_indices = []\n",
    "        out_distances = []\n",
    "        \n",
    "        for indice,distance in zip(indices, distances):\n",
    "            if ((wide_race_data.index[indice] in selection_idx) and (wide_race_data.index[indice] != similarTo)):\n",
    "                out_indices.append(indice)\n",
    "                out_distances.append(distance)\n",
    "                if len(out_distances) >=n :\n",
    "                    break\n",
    "    else:\n",
    "        out_indices = indices\n",
    "        out_distances = distances\n",
    "    \n",
    "    return [(wide_race_data.index[indice], distance) for indice,distance in zip(out_indices, out_distances)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cozumel', 0.8025092033167267),\n",
       " ('loscabos', 0.83877460460272),\n",
       " ('texas', 0.9342507987009557),\n",
       " ('boulder', 0.9582525085194594),\n",
       " ('arizona', 0.9712888708037406),\n",
       " ('florida', 0.9765996294538618),\n",
       " ('brazil', 0.9767572156401197),\n",
       " ('barcelona', 0.9832372723157605),\n",
       " ('canada', 0.9839421632454937),\n",
       " ('monttremblant', 0.9844497617180233)]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prediction('monterrey70.3', filterBy='is_70.3', value=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cozumel', 0.8025092033167267),\n",
       " ('loscabos', 0.83877460460272),\n",
       " ('texas', 0.9342507987009557),\n",
       " ('boulder', 0.9582525085194594),\n",
       " ('arizona', 0.9712888708037406),\n",
       " ('florida', 0.9765996294538618),\n",
       " ('brazil', 0.9767572156401197),\n",
       " ('barcelona', 0.9832372723157605),\n",
       " ('canada', 0.9839421632454937),\n",
       " ('monttremblant', 0.9844497617180233)]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prediction_fast('monterrey70.3', filterBy='is_70.3', value=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "Evaluation is important for machine learning projects, because it allows to compare objectivelly different algorithms and hyperparameter choices for models.\n",
    "One key aspect of evaluation is to ensure that the trained model generalizes for data it was not trained on, using Cross-validation techniques. We are using here a simple cross-validation approach named **holdout**, in which a random data sample (20% in this case) are kept aside in the training process, and exclusively used for evaluation. All evaluation metrics reported here are computed using the test set.\n",
    "\n",
    "Ps. A more robust evaluation approach could be to split train and test sets by a reference date, where the train set is composed by all interactions before that date, and the test set are interactions after that date. For the sake of simplicity, we chose the first random approach for this notebook, but you may want to try the second approach to better simulate how the recsys would perform in production predicting \"future\" users interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# results in Train set: 611908\n",
      "# interactions on Test set: 249935\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "results_df = results_data.copy()\n",
    "results_train_df, results_test_df = train_test_split(results_df,\n",
    "                                                     stratify=results_data['athlete'], \n",
    "                                                     test_size=0.29,\n",
    "                                                     random_state=42)\n",
    "\n",
    "print('# results in Train set: %d' % len(results_train_df))\n",
    "print('# interactions on Test set: %d' % len(results_test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Recommender Systems, there are a set metrics commonly used for evaluation. We chose to work with Top-N accuracy metrics, which evaluates the accuracy of the top recommendations provided to a user, comparing to the items the user has actually interacted in test set.\n",
    "\n",
    "**Note:** \n",
    "For what is to follow, we naively assume that if an individual has not done a race then it means the race is not relevant to him/her, which might not be true, as the individual may simply not be aware of the race or not had time to do it yet. But let's keep this assumption.\n",
    "\n",
    "This evaluation method works as follows:\n",
    "   * For each user\n",
    "   * For each result in test set (item the user has interacted with)\n",
    "   * Sample 100 other items the user has never interacted.\n",
    "   * Ask the recommender model to produce a ranked list of recommended races, from a set composed of one race raced by the individual and 100 races not raced (\"non-relevant!)\n",
    "   * Compute the Top-N accuracy metrics for this individual and interacted race from the recommendations ranked list\n",
    "   * Aggregate the global Top-N accuracy metrics\n",
    "   \n",
    "The Top-N accuracy metric choosen is **Recall@N** which evaluates whether the interacted race is among the top N races (hit) in the ranked list of 101 recommendations for an individual.\n",
    "\n",
    "**None:**\n",
    "Other popular ranking metrics are **NDCG@N** and **MAP@N**, whose score calculation takes into account the position of the relevant item in the ranked list (max. value if relevant item is in the first position). (see http://fastml.com/evaluating-recommender-systems/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Indexing by athleteID to speed up the searches during evaluation\n",
    "results_df = results_df.set_index('athlete')\n",
    "results_train_df = results_train_df.set_index('athlete')\n",
    "results_test_df = results_test_df.set_index('athlete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_races_for(athlete, results_df=results_df):\n",
    "    # Get the user's results and merge in the movie information.\n",
    "    interacted_races = results_df.loc[athlete]['race']\n",
    "    return set(interacted_races if type(interacted_races) == pd.Series else [interacted_races])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'brazil',\n",
       " 'california70.3',\n",
       " 'cozumel',\n",
       " 'honu70.3',\n",
       " 'loscabos',\n",
       " 'mardelplata',\n",
       " 'xiamen70.3'}"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_races_for('u0', results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top-N accuracy metrics consts\n",
    "EVAL_RANDOM_SAMPLE_NON_INTERACTED_RACES = 100\n",
    "\n",
    "import random\n",
    "\n",
    "class ModelEvaluator:\n",
    "\n",
    "    def get_not_interacted_races_sample(self, athlete_id, sample_size, seed=42):\n",
    "        interacted_races = get_races_for(athlete_id, results_df)\n",
    "        all_races = set(results_df['race'])\n",
    "        non_interacted_races = all_races - interacted_races\n",
    "\n",
    "        random.seed(seed)\n",
    "        non_interacted_races_sample = random.sample(non_interacted_races, sample_size)\n",
    "        return set(non_interacted_races_sample)\n",
    "\n",
    "    def _verify_hit_top_n(self, race_id, recommended_races, topn):        \n",
    "            try:\n",
    "                index = next(i for i, c in enumerate(recommended_races) if c == race_id)\n",
    "            except:\n",
    "                index = -1\n",
    "            hit = int(index in range(0, topn))\n",
    "            return hit, index\n",
    "\n",
    "    def evaluate_model_for_athlete(self, model, athlete_id):\n",
    "        # Getting the items in test set\n",
    "        interacted_races_testset = results_test_df.loc[athlete_id]\n",
    "        if type(interacted_races_testset['race']) == pd.Series:\n",
    "            athlete_interacted_races_testset = set(interacted_races_testset['race'])\n",
    "        else:\n",
    "            athlete_interacted_races_testset = set([interacted_races_testset['race']])  \n",
    "        interacted_races_count_testset = len(athlete_interacted_races_testset) \n",
    "\n",
    "        # Getting a ranked recommendation list from a model for a given user\n",
    "        athlete_recs_df = model.recommend_races(athlete_id, \n",
    "                                                items_to_ignore=get_races_for(athlete_id, results_train_df), \n",
    "                                                topn=10000000000)\n",
    "\n",
    "        hits_at_5_count = 0\n",
    "        hits_at_10_count = 0\n",
    "        # For each item the user has interacted in test set\n",
    "        for race_id in athlete_interacted_races_testset:\n",
    "            # Getting a random sample (100) raes the user has not interacted with\n",
    "            # (to represent rades that are assumed to be no relevant to the athlete)\n",
    "            non_interacted_races_sample = self.get_not_interacted_races_sample(athlete_id, \n",
    "                                                                               sample_size=EVAL_RANDOM_SAMPLE_NON_INTERACTED_RACES, \n",
    "                                                                               seed=race_filter.index.get_loc(race_id)%(2**32))\n",
    "\n",
    "            # Combining the current interacted item with the 100 random items\n",
    "            races_to_filter_recs = non_interacted_races_sample.union(set([race_id]))\n",
    "\n",
    "            # Filtering only recommendations that are either the interacted item or from a random sample of 100 non-interacted races\n",
    "            valid_recs_df = athlete_recs_df[athlete_recs_df['race'].isin(races_to_filter_recs)]                    \n",
    "            valid_recs = valid_recs_df['race'].values\n",
    "            # Verifying if the current interacted item is among the Top-N recommended items\n",
    "            hit_at_5, index_at_5 = self._verify_hit_top_n(race_id, valid_recs, 5)\n",
    "            hits_at_5_count += hit_at_5\n",
    "            hit_at_10, index_at_10 = self._verify_hit_top_n(race_id, valid_recs, 10)\n",
    "            hits_at_10_count += hit_at_10\n",
    "\n",
    "        # Recall is the rate of the interacted races that are ranked among the Top-N recommended races, \n",
    "        # when mixed with a set of non-relevant races\n",
    "        recall_at_5 = hits_at_5_count / float(interacted_races_count_testset)\n",
    "        recall_at_10 = hits_at_10_count / float(interacted_races_count_testset)\n",
    "\n",
    "        athlete_metrics = {'hits@5_count':hits_at_5_count, \n",
    "                           'hits@10_count':hits_at_10_count, \n",
    "                           'interacted_count': interacted_races_count_testset,\n",
    "                           'recall@5': recall_at_5,\n",
    "                           'recall@10': recall_at_10}\n",
    "        return athlete_metrics\n",
    "\n",
    "    def evaluate_model(self, model, limit=False):\n",
    "        # print('Running evaluation for athlete')\n",
    "        individual_metrics = []\n",
    "        limit = len(results_test_df.index.unique()) if not limit else limit\n",
    "        for idx, athlete_id in enumerate(list(results_test_df.index.unique().values)[:limit]):\n",
    "            #if idx % 100 == 0 and idx > 0:\n",
    "            #    print('%d users processed' % idx)\n",
    "            athlete_metrics = self.evaluate_model_for_athlete(model, athlete_id)  \n",
    "            athlete_metrics['athlete'] = athlete_id\n",
    "            individual_metrics.append(athlete_metrics)\n",
    "        print(f'{idx} users processed')\n",
    "\n",
    "        detailed_results_df = pd.DataFrame(individual_metrics) \\\n",
    "                                .sort_values('interacted_count', ascending=False)\n",
    "        \n",
    "        global_recall_at_5 = detailed_results_df['hits@5_count'].sum() / float(detailed_results_df['interacted_count'].sum())\n",
    "        global_recall_at_10 = detailed_results_df['hits@10_count'].sum() / float(detailed_results_df['interacted_count'].sum())\n",
    "        \n",
    "        global_metrics = {'modelName': model.get_model_name(),\n",
    "                          'recall@5': global_recall_at_5,\n",
    "                          'recall@10': global_recall_at_10}    \n",
    "        return global_metrics, detailed_results_df\n",
    "    \n",
    "model_evaluator = ModelEvaluator()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Popularity model\n",
    "A common (and usually hard-to-beat) baseline approach is the Popularity model. This model is not actually personalized - it simply recommends to a user the most popular items that the user has not previously consumed. As the popularity accounts for the \"wisdom of the crowds\", it usually provides good recommendations, generally interesting for most people.\n",
    "Ps. The main objective of a recommender system is to leverage the long-tail items to the users with very specific interests, which goes far beyond this simple technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>florida</td>\n",
       "      <td>38737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lakeplacid</td>\n",
       "      <td>32840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arizona</td>\n",
       "      <td>31671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wisconsin</td>\n",
       "      <td>30063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>california70.3</td>\n",
       "      <td>29870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>austria</td>\n",
       "      <td>27098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>louisville</td>\n",
       "      <td>26663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>florida70.3</td>\n",
       "      <td>24087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>canada</td>\n",
       "      <td>23619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>augusta70.3</td>\n",
       "      <td>22627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             race  count\n",
       "0         florida  38737\n",
       "1      lakeplacid  32840\n",
       "2         arizona  31671\n",
       "3       wisconsin  30063\n",
       "4  california70.3  29870\n",
       "5         austria  27098\n",
       "6      louisville  26663\n",
       "7     florida70.3  24087\n",
       "8          canada  23619\n",
       "9     augusta70.3  22627"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Computes the most popular races\n",
    "races_popularity_df = results_df.groupby('race')['count'].sum().sort_values(ascending=False).reset_index()\n",
    "races_popularity_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PopularityRecommender:\n",
    "    \n",
    "    MODEL_NAME = 'Popularity'\n",
    "    \n",
    "    def __init__(self, popularity_df, items_df=None):\n",
    "        self.popularity_df = popularity_df\n",
    "        self.items_df = items_df\n",
    "        \n",
    "    def get_model_name(self):\n",
    "        return self.MODEL_NAME\n",
    "        \n",
    "    def recommend_races(self, athlete_id, items_to_ignore=[], topn=10, verbose=False):\n",
    "        # Recommend the more popular items that the user hasn't seen yet.\n",
    "        recommendations_df = self.popularity_df[~self.popularity_df['race'].isin(items_to_ignore)] \\\n",
    "                               .sort_values('count', ascending = False) \\\n",
    "                               .head(topn)\n",
    "        if verbose:\n",
    "            if self.items_df is None:\n",
    "                raise Exception('\"items_df\" is required in verbose mode')\n",
    "\n",
    "            recommendations_df = recommendations_df.merge(self.items_df, how = 'left', \n",
    "                                                          left_on = 'race', \n",
    "                                                          right_on = 'race')[['count', 'race']]\n",
    "\n",
    "\n",
    "        return recommendations_df\n",
    "    \n",
    "popularity_model = PopularityRecommender(races_popularity_df, race_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Popularity recommendation model...\n",
      "99 users processed\n",
      "\n",
      "Global metrics:\n",
      "{'modelName': 'Popularity', 'recall@5': 0.16875, 'recall@10': 0.3125}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>athlete</th>\n",
       "      <th>hits@10_count</th>\n",
       "      <th>hits@5_count</th>\n",
       "      <th>interacted_count</th>\n",
       "      <th>recall@10</th>\n",
       "      <th>recall@5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>u24377</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>u122996</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>u35509</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>u84074</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>u16289</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>u87147</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>u6605</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>u178078</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u22567</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    athlete  hits@10_count  hits@5_count  interacted_count  recall@10  \\\n",
       "35   u24377              7             5                10   0.700000   \n",
       "33  u122996              1             1                 5   0.200000   \n",
       "96   u35509              3             2                 4   0.750000   \n",
       "3       u30              1             1                 4   0.250000   \n",
       "88   u84074              3             1                 4   0.750000   \n",
       "38   u16289              2             0                 3   0.666667   \n",
       "76   u87147              1             1                 3   0.333333   \n",
       "24    u6605              0             0                 3   0.000000   \n",
       "26  u178078              1             1                 3   0.333333   \n",
       "1    u22567              1             1                 3   0.333333   \n",
       "\n",
       "    recall@5  \n",
       "35  0.500000  \n",
       "33  0.200000  \n",
       "96  0.500000  \n",
       "3   0.250000  \n",
       "88  0.250000  \n",
       "38  0.000000  \n",
       "76  0.333333  \n",
       "24  0.000000  \n",
       "26  0.333333  \n",
       "1   0.333333  "
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Evaluating Popularity recommendation model...')\n",
    "pop_global_metrics, pop_detailed_results_df = model_evaluator.evaluate_model(popularity_model, limit=100)\n",
    "print('\\nGlobal metrics:\\n%s' % pop_global_metrics)\n",
    "pop_detailed_results_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative-based filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollaborativeBasedRecommender:\n",
    "    \n",
    "    MODEL_NAME = 'Collaborative-Based'\n",
    "    \n",
    "    def __init__(self, items_df=None):\n",
    "        self.items_df = items_df\n",
    "        \n",
    "    def get_model_name(self):\n",
    "        return self.MODEL_NAME\n",
    "        \n",
    "    def recommend_races(self, athlete_id, items_to_ignore=[], topn=10, verbose=False):\n",
    "        similar_races = [rec[0] for rec in list(get_prediction_fast(list(items_to_ignore)[0], n=100))]\n",
    "        \n",
    "        similar_races_filtered = []\n",
    "        for race in similar_races:\n",
    "            if race not in list(items_to_ignore):\n",
    "                similar_races_filtered.append(race)\n",
    "        \n",
    "        recommendations_df = race_filter.loc[similar_races_filtered]\n",
    "        recommendations_df['race'] = recommendations_df.index\n",
    "        recommendations_df = recommendations_df.head(topn)\n",
    "\n",
    "        return recommendations_df\n",
    "    \n",
    "collaborative_based_recommender_model = CollaborativeBasedRecommender(race_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Collaborative-Based Filtering model...\n",
      "99 users processed\n",
      "\n",
      "Global metrics:\n",
      "{'modelName': 'Collaborative-Based', 'recall@5': 0.4125, 'recall@10': 0.58125}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>athlete</th>\n",
       "      <th>hits@10_count</th>\n",
       "      <th>hits@5_count</th>\n",
       "      <th>interacted_count</th>\n",
       "      <th>recall@10</th>\n",
       "      <th>recall@5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>u24377</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>u122996</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>u35509</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u30</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>u84074</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>u16289</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>u87147</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>u6605</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>u178078</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u22567</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>u103322</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>u72450</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>u10881</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u45830</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>u62445</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    athlete  hits@10_count  hits@5_count  interacted_count  recall@10  \\\n",
       "35   u24377              1             1                10   0.100000   \n",
       "33  u122996              2             1                 5   0.400000   \n",
       "96   u35509              2             1                 4   0.500000   \n",
       "3       u30              2             2                 4   0.500000   \n",
       "88   u84074              3             3                 4   0.750000   \n",
       "38   u16289              2             1                 3   0.666667   \n",
       "76   u87147              0             0                 3   0.000000   \n",
       "24    u6605              1             1                 3   0.333333   \n",
       "26  u178078              0             0                 3   0.000000   \n",
       "1    u22567              1             1                 3   0.333333   \n",
       "8   u103322              2             1                 3   0.666667   \n",
       "6    u72450              1             0                 3   0.333333   \n",
       "83   u10881              2             1                 3   0.666667   \n",
       "4    u45830              1             1                 3   0.333333   \n",
       "29   u62445              1             1                 2   0.500000   \n",
       "\n",
       "    recall@5  \n",
       "35  0.100000  \n",
       "33  0.200000  \n",
       "96  0.250000  \n",
       "3   0.500000  \n",
       "88  0.750000  \n",
       "38  0.333333  \n",
       "76  0.000000  \n",
       "24  0.333333  \n",
       "26  0.000000  \n",
       "1   0.333333  \n",
       "8   0.333333  \n",
       "6   0.000000  \n",
       "83  0.333333  \n",
       "4   0.333333  \n",
       "29  0.500000  "
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Evaluating Collaborative-Based Filtering model...')\n",
    "cf_global_metrics, cf_detailed_results_df = model_evaluator.evaluate_model(collaborative_based_recommender_model, limit=100)\n",
    "print('\\nGlobal metrics:\\n%s' % cf_global_metrics)\n",
    "cf_detailed_results_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hits@10_count       0.500000\n",
       "hits@5_count        0.270000\n",
       "interacted_count    1.600000\n",
       "recall@10           0.276500\n",
       "recall@5            0.145333\n",
       "dtype: float64"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop_detailed_results_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hits@10_count       0.930000\n",
       "hits@5_count        0.660000\n",
       "interacted_count    1.600000\n",
       "recall@10           0.655833\n",
       "recall@5            0.463000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_detailed_results_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to weight according to how many times they came back to the race"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix factorization\n",
    "\n",
    "Latent factor models compress user-item matrix into a low-dimensional representation in terms of latent factors. One advantage of using this approach is that instead of having a high dimensional matrix containing abundant number of missing values we will be dealing with a much smaller matrix in lower-dimensional space.\n",
    "A reduced presentation could be utilized for either user-based or item-based neighborhood algorithms that are presented in the previous section. There are several advantages with this paradigm. It handles the sparsity of the original matrix better than memory based ones. Also comparing similarity on the resulting matrix is much more scalable especially in dealing with large sparse datasets.\n",
    "\n",
    "Here we a use popular latent factor model named **Singular Value Decomposition (SVD)**. There are other matrix factorization frameworks more specific to CF you might try, like surprise, mrec or python-recsys. We chose a SciPy implemenation of SVD.\n",
    "\n",
    "An important decision is the number of factors to factor the user-item matrix. The higher the number of factors, the more precise is the factorization in the original matrix reconstructions. Therefore, if the model is allowed to memorize too much details of the original matrix, it may not generalize well for data it was not trained on. Reducing the number of factors increases the model generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/miniconda3/envs/data-science/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 2.],\n",
       "       [0., 0., 0., ..., 0., 0., 3.],\n",
       "       [0., 0., 0., ..., 0., 0., 2.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_items_pivot_matrix_df = wide_race_data.transpose()\n",
    "\n",
    "users_items_pivot_matrix = users_items_pivot_matrix_df.as_matrix()\n",
    "users_items_pivot_matrix[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['u0',\n",
       " 'u1',\n",
       " 'u10',\n",
       " 'u100',\n",
       " 'u1000',\n",
       " 'u10000',\n",
       " 'u100000',\n",
       " 'u100001',\n",
       " 'u100002',\n",
       " 'u100003']"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_ids = list(users_items_pivot_matrix_df.index)\n",
    "users_ids[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "#The number of factors to factor the user-item matrix.\n",
    "NUMBER_OF_FACTORS_MF = 15\n",
    "#Performs matrix factorization of the original user item matrix\n",
    "U, sigma, Vt = svds(users_items_pivot_matrix, k = NUMBER_OF_FACTORS_MF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(248360, 15)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 153)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 15)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma = np.diag(sigma)\n",
    "sigma.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the factorization, we try to to reconstruct the original matrix by multiplying its factors. The resulting matrix is not sparse any more. It was generated predictions for items the user have not yet interaction, which we will exploit for recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.07394962e-02,  1.29402173e-03,  1.14687061e-02, ...,\n",
       "         9.69302555e-02,  2.92933203e-03,  4.37491612e-03],\n",
       "       [-1.11817607e-02,  1.75333806e-03, -1.44182769e-03, ...,\n",
       "         4.90459775e-02, -9.69355913e-04,  5.99929411e-03],\n",
       "       [-1.68667914e-04,  5.86450508e-04, -6.61958583e-05, ...,\n",
       "        -4.08357737e-04,  2.27921663e-04,  1.01392228e-03],\n",
       "       ...,\n",
       "       [ 1.21201854e-03,  9.16305856e-03,  5.23239268e-04, ...,\n",
       "        -5.22992076e-03,  3.17635262e-03,  1.46481527e-02],\n",
       "       [-1.05097017e-04,  5.44234311e-03,  1.78425339e-03, ...,\n",
       "        -2.37481399e-02,  4.02576346e-03,  9.47793852e-03],\n",
       "       [-1.04837475e-03,  2.31242220e-03, -8.88217567e-04, ...,\n",
       "        -4.95199364e-03,  1.59470880e-03,  3.96830514e-03]])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_user_predicted_ratings = np.dot(np.dot(U, sigma), Vt) \n",
    "all_user_predicted_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u0</th>\n",
       "      <th>u1</th>\n",
       "      <th>u10</th>\n",
       "      <th>u100</th>\n",
       "      <th>u1000</th>\n",
       "      <th>u10000</th>\n",
       "      <th>u100000</th>\n",
       "      <th>u100001</th>\n",
       "      <th>u100002</th>\n",
       "      <th>u100003</th>\n",
       "      <th>...</th>\n",
       "      <th>u99990</th>\n",
       "      <th>u99991</th>\n",
       "      <th>u99992</th>\n",
       "      <th>u99993</th>\n",
       "      <th>u99994</th>\n",
       "      <th>u99995</th>\n",
       "      <th>u99996</th>\n",
       "      <th>u99997</th>\n",
       "      <th>u99998</th>\n",
       "      <th>u99999</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Arizona70.3</th>\n",
       "      <td>0.030739</td>\n",
       "      <td>-0.011182</td>\n",
       "      <td>-0.000169</td>\n",
       "      <td>-0.014285</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>-0.002021</td>\n",
       "      <td>-0.002097</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.002425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000816</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>0.004523</td>\n",
       "      <td>-0.000032</td>\n",
       "      <td>-0.003591</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.001212</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.001048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DunLaoghaire70.3</th>\n",
       "      <td>0.001294</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.002837</td>\n",
       "      <td>0.003810</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.007315</td>\n",
       "      <td>0.004625</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>0.003209</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002657</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>0.003009</td>\n",
       "      <td>0.004402</td>\n",
       "      <td>0.001525</td>\n",
       "      <td>0.009163</td>\n",
       "      <td>0.005442</td>\n",
       "      <td>0.002312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Florianopolis70.3</th>\n",
       "      <td>0.011469</td>\n",
       "      <td>-0.001442</td>\n",
       "      <td>-0.000066</td>\n",
       "      <td>-0.001059</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>-0.000506</td>\n",
       "      <td>-0.001791</td>\n",
       "      <td>-0.001776</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>-0.001186</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000715</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>-0.000054</td>\n",
       "      <td>0.012130</td>\n",
       "      <td>0.000821</td>\n",
       "      <td>-0.000887</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.001784</td>\n",
       "      <td>-0.000888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Haugesund70.3</th>\n",
       "      <td>0.002943</td>\n",
       "      <td>0.001574</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>0.002073</td>\n",
       "      <td>0.012103</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.001954</td>\n",
       "      <td>0.001603</td>\n",
       "      <td>0.001361</td>\n",
       "      <td>0.003368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>0.001461</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>0.006668</td>\n",
       "      <td>0.006966</td>\n",
       "      <td>0.003894</td>\n",
       "      <td>0.008930</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>0.000802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IMsubicbay</th>\n",
       "      <td>0.002298</td>\n",
       "      <td>0.004318</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>0.002746</td>\n",
       "      <td>0.001167</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.010106</td>\n",
       "      <td>0.006204</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.004333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003652</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.001965</td>\n",
       "      <td>0.004601</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>0.010283</td>\n",
       "      <td>0.007453</td>\n",
       "      <td>0.003102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maastricht</th>\n",
       "      <td>0.006137</td>\n",
       "      <td>0.003318</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>0.011071</td>\n",
       "      <td>0.026917</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.008525</td>\n",
       "      <td>0.005955</td>\n",
       "      <td>0.003071</td>\n",
       "      <td>0.009502</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003153</td>\n",
       "      <td>0.003334</td>\n",
       "      <td>0.000847</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.016732</td>\n",
       "      <td>0.008883</td>\n",
       "      <td>0.024052</td>\n",
       "      <td>0.004773</td>\n",
       "      <td>0.002977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nice70.3</th>\n",
       "      <td>0.004928</td>\n",
       "      <td>-0.002370</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.002235</td>\n",
       "      <td>0.017196</td>\n",
       "      <td>-0.000118</td>\n",
       "      <td>0.001532</td>\n",
       "      <td>0.001282</td>\n",
       "      <td>0.001907</td>\n",
       "      <td>0.004245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>0.002040</td>\n",
       "      <td>0.001186</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>0.010146</td>\n",
       "      <td>0.007996</td>\n",
       "      <td>0.006392</td>\n",
       "      <td>0.012645</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>0.000641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vietnam70.3</th>\n",
       "      <td>0.005437</td>\n",
       "      <td>0.011531</td>\n",
       "      <td>0.002260</td>\n",
       "      <td>0.007331</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.030058</td>\n",
       "      <td>0.018543</td>\n",
       "      <td>0.000920</td>\n",
       "      <td>0.012364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010872</td>\n",
       "      <td>0.000907</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.001085</td>\n",
       "      <td>0.007239</td>\n",
       "      <td>0.014563</td>\n",
       "      <td>0.002354</td>\n",
       "      <td>0.031986</td>\n",
       "      <td>0.021742</td>\n",
       "      <td>0.009271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alagoas70.3</th>\n",
       "      <td>0.020083</td>\n",
       "      <td>-0.002226</td>\n",
       "      <td>-0.000112</td>\n",
       "      <td>-0.001943</td>\n",
       "      <td>0.001208</td>\n",
       "      <td>-0.000855</td>\n",
       "      <td>-0.003150</td>\n",
       "      <td>-0.003088</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>-0.001997</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001254</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>0.021131</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>-0.001448</td>\n",
       "      <td>0.005573</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.003005</td>\n",
       "      <td>-0.001544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arizona</th>\n",
       "      <td>-0.104917</td>\n",
       "      <td>-0.281677</td>\n",
       "      <td>-0.004244</td>\n",
       "      <td>0.008369</td>\n",
       "      <td>0.001921</td>\n",
       "      <td>-0.003052</td>\n",
       "      <td>-0.049921</td>\n",
       "      <td>-0.045432</td>\n",
       "      <td>-0.003357</td>\n",
       "      <td>0.028160</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019520</td>\n",
       "      <td>-0.004092</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>-0.000035</td>\n",
       "      <td>-0.007369</td>\n",
       "      <td>-0.098708</td>\n",
       "      <td>-0.016288</td>\n",
       "      <td>-0.002357</td>\n",
       "      <td>-0.018158</td>\n",
       "      <td>-0.022716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 248360 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         u0        u1       u10      u100     u1000    u10000  \\\n",
       "race                                                                            \n",
       "Arizona70.3        0.030739 -0.011182 -0.000169 -0.014285  0.000095  0.000812   \n",
       "DunLaoghaire70.3   0.001294  0.001753  0.000586  0.002837  0.003810  0.000319   \n",
       "Florianopolis70.3  0.011469 -0.001442 -0.000066 -0.001059  0.000677 -0.000506   \n",
       "Haugesund70.3      0.002943  0.001574  0.000358  0.002073  0.012103  0.000101   \n",
       "IMsubicbay         0.002298  0.004318  0.000747  0.002746  0.001167  0.000079   \n",
       "Maastricht         0.006137  0.003318  0.001080  0.011071  0.026917  0.000070   \n",
       "Nice70.3           0.004928 -0.002370  0.000376  0.002235  0.017196 -0.000118   \n",
       "Vietnam70.3        0.005437  0.011531  0.002260  0.007331  0.006150  0.000270   \n",
       "alagoas70.3        0.020083 -0.002226 -0.000112 -0.001943  0.001208 -0.000855   \n",
       "arizona           -0.104917 -0.281677 -0.004244  0.008369  0.001921 -0.003052   \n",
       "\n",
       "                    u100000   u100001   u100002   u100003  ...    u99990  \\\n",
       "race                                                       ...             \n",
       "Arizona70.3       -0.002021 -0.002097 -0.000010 -0.002425  ... -0.000816   \n",
       "DunLaoghaire70.3   0.007315  0.004625  0.000522  0.003209  ...  0.002657   \n",
       "Florianopolis70.3 -0.001791 -0.001776  0.000231 -0.001186  ... -0.000715   \n",
       "Haugesund70.3      0.001954  0.001603  0.001361  0.003368  ...  0.000747   \n",
       "IMsubicbay         0.010106  0.006204  0.000190  0.004333  ...  0.003652   \n",
       "Maastricht         0.008525  0.005955  0.003071  0.009502  ...  0.003153   \n",
       "Nice70.3           0.001532  0.001282  0.001907  0.004245  ...  0.000588   \n",
       "Vietnam70.3        0.030058  0.018543  0.000920  0.012364  ...  0.010872   \n",
       "alagoas70.3       -0.003150 -0.003088  0.000417 -0.001997  ... -0.001254   \n",
       "arizona           -0.049921 -0.045432 -0.003357  0.028160  ... -0.019520   \n",
       "\n",
       "                     u99991    u99992    u99993    u99994    u99995    u99996  \\\n",
       "race                                                                            \n",
       "Arizona70.3       -0.000084  0.001006  0.004523 -0.000032 -0.003591  0.000491   \n",
       "DunLaoghaire70.3   0.000545  0.000509  0.000794  0.003009  0.004402  0.001525   \n",
       "Florianopolis70.3  0.000213 -0.000054  0.012130  0.000821 -0.000887  0.003166   \n",
       "Haugesund70.3      0.001461  0.000280  0.000551  0.006668  0.006966  0.003894   \n",
       "IMsubicbay         0.000179  0.000054  0.000230  0.001965  0.004601  0.000510   \n",
       "Maastricht         0.003334  0.000847  0.000211  0.015385  0.016732  0.008883   \n",
       "Nice70.3           0.002040  0.001186  0.000998  0.010146  0.007996  0.006392   \n",
       "Vietnam70.3        0.000907  0.000122  0.001085  0.007239  0.014563  0.002354   \n",
       "alagoas70.3        0.000385 -0.000084  0.021131  0.001411 -0.001448  0.005573   \n",
       "arizona           -0.004092  0.000503 -0.000035 -0.007369 -0.098708 -0.016288   \n",
       "\n",
       "                     u99997    u99998    u99999  \n",
       "race                                             \n",
       "Arizona70.3        0.001212 -0.000105 -0.001048  \n",
       "DunLaoghaire70.3   0.009163  0.005442  0.002312  \n",
       "Florianopolis70.3  0.000523  0.001784 -0.000888  \n",
       "Haugesund70.3      0.008930  0.000368  0.000802  \n",
       "IMsubicbay         0.010283  0.007453  0.003102  \n",
       "Maastricht         0.024052  0.004773  0.002977  \n",
       "Nice70.3           0.012645  0.002002  0.000641  \n",
       "Vietnam70.3        0.031986  0.021742  0.009271  \n",
       "alagoas70.3        0.000842  0.003005 -0.001544  \n",
       "arizona           -0.002357 -0.018158 -0.022716  \n",
       "\n",
       "[10 rows x 248360 columns]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Converting the reconstructed matrix back to a Pandas dataframe\n",
    "cf_preds_df = pd.DataFrame(all_user_predicted_ratings, columns = users_items_pivot_matrix_df.columns, index=users_ids).transpose()\n",
    "cf_preds_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "248360"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cf_preds_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFRecommender:\n",
    "    \n",
    "    MODEL_NAME = 'Collaborative Filtering'\n",
    "    \n",
    "    def __init__(self, cf_predictions_df, items_df=None):\n",
    "        self.cf_predictions_df = cf_predictions_df\n",
    "        self.items_df = items_df\n",
    "        \n",
    "    def get_model_name(self):\n",
    "        return self.MODEL_NAME\n",
    "        \n",
    "    def recommend_races(self, user_id, items_to_ignore=[], topn=10, verbose=False):\n",
    "        # Get and sort the user's predictions\n",
    "        sorted_user_predictions = self.cf_predictions_df[user_id].sort_values(ascending=False) \\\n",
    "                                    .reset_index().rename(columns={user_id: 'count'})\n",
    "\n",
    "        # Recommend the highest predicted rating movies that the user hasn't seen yet.\n",
    "        recommendations_df = sorted_user_predictions[~sorted_user_predictions['race'].isin(items_to_ignore)] \\\n",
    "                               .sort_values('count', ascending = False) \\\n",
    "                               .head(topn)\n",
    "\n",
    "        if verbose:\n",
    "            if self.items_df is None:\n",
    "                raise Exception('\"items_df\" is required in verbose mode')\n",
    "\n",
    "            recommendations_df = recommendations_df.merge(self.items_df, how = 'left', \n",
    "                                                          left_on = 'race', \n",
    "                                                          right_on = 'race')[['count', 'race']]\n",
    "\n",
    "\n",
    "        return recommendations_df\n",
    "    \n",
    "cf_svd_recommender_model = CFRecommender(cf_preds_df, race_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Collaborative Filtering (SVD Matrix Factorization) model...\n",
      "99 users processed\n",
      "\n",
      "Global metrics:\n",
      "{'modelName': 'Collaborative Filtering', 'recall@5': 0.55625, 'recall@10': 0.7125}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>athlete</th>\n",
       "      <th>hits@10_count</th>\n",
       "      <th>hits@5_count</th>\n",
       "      <th>interacted_count</th>\n",
       "      <th>recall@10</th>\n",
       "      <th>recall@5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>u24377</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>u122996</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>u35509</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>u84074</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>u16289</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>u87147</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>u6605</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>u178078</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u22567</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    athlete  hits@10_count  hits@5_count  interacted_count  recall@10  \\\n",
       "35   u24377              8             7                10   0.800000   \n",
       "33  u122996              3             2                 5   0.600000   \n",
       "96   u35509              3             2                 4   0.750000   \n",
       "3       u30              1             1                 4   0.250000   \n",
       "88   u84074              4             4                 4   1.000000   \n",
       "38   u16289              3             2                 3   1.000000   \n",
       "76   u87147              2             2                 3   0.666667   \n",
       "24    u6605              1             0                 3   0.333333   \n",
       "26  u178078              1             1                 3   0.333333   \n",
       "1    u22567              3             3                 3   1.000000   \n",
       "\n",
       "    recall@5  \n",
       "35  0.700000  \n",
       "33  0.400000  \n",
       "96  0.500000  \n",
       "3   0.250000  \n",
       "88  1.000000  \n",
       "38  0.666667  \n",
       "76  0.666667  \n",
       "24  0.000000  \n",
       "26  0.333333  \n",
       "1   1.000000  "
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Evaluating Collaborative Filtering (SVD Matrix Factorization) model...')\n",
    "cf_svd_global_metrics, cf_svd_detailed_results_df = model_evaluator.evaluate_model(cf_svd_recommender_model, limit=100)\n",
    "print('\\nGlobal metrics:\\n%s' % cf_svd_global_metrics)\n",
    "cf_svd_detailed_results_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>CF_sparse</th>\n",
       "      <th>CF_SVD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hits@10_count</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>1.140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hits@5_count</th>\n",
       "      <td>0.270000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interacted_count</th>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall@10</th>\n",
       "      <td>0.276500</td>\n",
       "      <td>0.655833</td>\n",
       "      <td>0.719000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall@5</th>\n",
       "      <td>0.145333</td>\n",
       "      <td>0.463000</td>\n",
       "      <td>0.581833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  popularity  CF_sparse    CF_SVD\n",
       "hits@10_count       0.500000   0.930000  1.140000\n",
       "hits@5_count        0.270000   0.660000  0.890000\n",
       "interacted_count    1.600000   1.600000  1.600000\n",
       "recall@10           0.276500   0.655833  0.719000\n",
       "recall@5            0.145333   0.463000  0.581833"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\n",
    "    \"popularity\": pop_detailed_results_df.mean(), \n",
    "    \"CF_sparse\": cf_detailed_results_df.mean(), \n",
    "    \"CF_SVD\": cf_svd_detailed_results_df.mean()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (data-science)",
   "language": "python",
   "name": "data-science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
